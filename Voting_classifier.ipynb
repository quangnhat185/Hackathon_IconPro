{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voting_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "import os\n",
        "seed(23)\n",
        "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
        "np.random.seed(23)\n",
        "tf.random.set_seed(23)"
      ],
      "metadata": {
        "id": "0aHNJO6pUkcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8HhNH7tf5lm"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLXvoeolInoC",
        "outputId": "63e756c4-e77c-485c-a789-f93e6454e532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ./drive/MyDrive/ICNA_hackathon/ ./\n",
        "!unzip ./ICNA_hackathon/FordA.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZK69oSzgEYU",
        "outputId": "b4dbb4c3-f5d4-4aaf-de2c-4b7deb68a7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./ICNA_hackathon/FordA.zip\n",
            "   creating: FordA/\n",
            "  inflating: FordA/config.json       \n",
            "  inflating: FordA/data.pkl          \n",
            "  inflating: FordA/FordA_TEST.ts     \n",
            "  inflating: FordA/FordA_TRAIN.ts    \n",
            "   creating: FordA/.ipynb_checkpoints/\n",
            "  inflating: FordA/.ipynb_checkpoints/config-checkpoint.json  \n",
            "  inflating: FordA/.ipynb_checkpoints/FordA_TEST-checkpoint.ts  \n",
            "  inflating: FordA/.ipynb_checkpoints/FordA_TRAIN-checkpoint.ts  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from helper import Helper\n",
        "\n",
        "helper = Helper()\n",
        "file_train = \"./FordA/FordA_TRAIN.ts\"\n",
        "file_test = \"./FordA/FordA_TEST.ts\"\n",
        "x_train, y_train = helper.data_processing(file_train)\n",
        "x_test, y_test = helper.data_processing(file_test)\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "idx = np.random.permutation(len(x_train))\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0\n",
        "\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hcnyDK7gV2o",
        "outputId": "9b6c4880-eb32-43b2-b92a-5b1446230134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3601, 500, 1)\n",
            "(3601,)\n",
            "(1320, 500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip pretrained transformer_time2vec model\n",
        "\n",
        "# !cp -r ./drive/MyDrive/ICNA_hackathon/ ./\n",
        "!tar -xvf ./ICNA_hackathon/transformer_time2vec.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhbPPPDnK7dI",
        "outputId": "6a5b1bb8-aea7-42cf-aad8-b5668a18bee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./transformer_time2vec/\n",
            "./transformer_time2vec/keras_metadata.pb\n",
            "./transformer_time2vec/variables/\n",
            "./transformer_time2vec/variables/variables.index\n",
            "./transformer_time2vec/variables/variables.data-00000-of-00001\n",
            "./transformer_time2vec/saved_model.pb\n",
            "./transformer_time2vec/assets/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Time2Vector(Layer):\n",
        "  def __init__(self, seq_len, **kwargs):\n",
        "    super(Time2Vector, self).__init__()\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    '''Initialize weights and biases with shape (batch, seq_len)'''\n",
        "    self.weights_linear = self.add_weight(name='weight_linear',\n",
        "                                shape=(int(self.seq_len),),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "    \n",
        "    self.bias_linear = self.add_weight(name='bias_linear',\n",
        "                                shape=(int(self.seq_len),),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "    \n",
        "    self.weights_periodic = self.add_weight(name='weight_periodic',\n",
        "                                shape=(int(self.seq_len),),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "\n",
        "    self.bias_periodic = self.add_weight(name='bias_periodic',\n",
        "                                shape=(int(self.seq_len),),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "\n",
        "  def call(self, x):\n",
        "    '''Calculate linear and periodic time features'''\n",
        "    x = tf.math.reduce_mean(x[:,:,:], axis=-1) \n",
        "    time_linear = self.weights_linear * x + self.bias_linear # Linear time feature\n",
        "    time_linear = tf.expand_dims(time_linear, axis=-1) # Add dimension (batch, seq_len, 1)\n",
        "    \n",
        "    time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
        "    time_periodic = tf.expand_dims(time_periodic, axis=-1) # Add dimension (batch, seq_len, 1)\n",
        "    return tf.concat([time_linear, time_periodic], axis=-1) # shape = (batch, seq_len, 2)\n",
        "   \n",
        "  def get_config(self): # Needed for saving and loading model with custom layer\n",
        "    config = super().get_config().copy()\n",
        "    config.update({'seq_len': self.seq_len})\n",
        "    return config\n",
        "  "
      ],
      "metadata": {
        "id": "Wh8S6zM2KH3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleAttention(Layer):\n",
        "  def __init__(self, d_k, d_v):\n",
        "    super(SingleAttention, self).__init__()\n",
        "    self.d_k = d_k\n",
        "    self.d_v = d_v\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.query = Dense(self.d_k, \n",
        "                       input_shape=input_shape, \n",
        "                       kernel_initializer='glorot_uniform', \n",
        "                       bias_initializer='glorot_uniform')\n",
        "    \n",
        "    self.key = Dense(self.d_k, \n",
        "                     input_shape=input_shape, \n",
        "                     kernel_initializer='glorot_uniform', \n",
        "                     bias_initializer='glorot_uniform')\n",
        "    \n",
        "    self.value = Dense(self.d_v, \n",
        "                       input_shape=input_shape, \n",
        "                       kernel_initializer='glorot_uniform', \n",
        "                       bias_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
        "    q = self.query(inputs[0])\n",
        "    k = self.key(inputs[1])\n",
        "\n",
        "    attn_weights = tf.matmul(q, k, transpose_b=True)\n",
        "    attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
        "    attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
        "    \n",
        "    v = self.value(inputs[2])\n",
        "    attn_out = tf.matmul(attn_weights, v)\n",
        "    return attn_out    \n",
        "\n",
        "#############################################################################\n",
        "\n",
        "class MultiAttention(Layer):\n",
        "  def __init__(self, d_k, d_v, n_heads):\n",
        "    super(MultiAttention, self).__init__()\n",
        "    self.d_k = d_k\n",
        "    self.d_v = d_v\n",
        "    self.n_heads = n_heads\n",
        "    self.attn_heads = list()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    for n in range(self.n_heads):\n",
        "      self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \n",
        "    \n",
        "    # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7 \n",
        "    self.linear = Dense(input_shape[0][-1], \n",
        "                        input_shape=input_shape, \n",
        "                        kernel_initializer='glorot_uniform', \n",
        "                        bias_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
        "    concat_attn = tf.concat(attn, axis=-1)\n",
        "    multi_linear = self.linear(concat_attn)\n",
        "    return multi_linear   \n",
        "\n",
        "#############################################################################\n",
        "\n",
        "class TransformerEncoder(Layer):\n",
        "  def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
        "    super(TransformerEncoder, self).__init__()\n",
        "    self.d_k = d_k\n",
        "    self.d_v = d_v\n",
        "    self.n_heads = n_heads\n",
        "    self.ff_dim = ff_dim\n",
        "    self.attn_heads = list()\n",
        "    self.dropout_rate = dropout\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
        "    self.attn_dropout = Dropout(self.dropout_rate)\n",
        "    self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
        "\n",
        "    self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
        "    # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1] = 7 \n",
        "    self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) \n",
        "    self.ff_dropout = Dropout(self.dropout_rate)\n",
        "    self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
        "  \n",
        "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
        "    attn_layer = self.attn_multi(inputs)\n",
        "    attn_layer = self.attn_dropout(attn_layer)\n",
        "    attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
        "\n",
        "    ff_layer = self.ff_conv1D_1(attn_layer)\n",
        "    ff_layer = self.ff_conv1D_2(ff_layer)\n",
        "    ff_layer = self.ff_dropout(ff_layer)\n",
        "    ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
        "    return ff_layer \n",
        "\n",
        "  def get_config(self): # Needed for saving and loading model with custom layer\n",
        "    config = super().get_config().copy()\n",
        "    config.update({'d_k': self.d_k,\n",
        "                   'd_v': self.d_v,\n",
        "                   'n_heads': self.n_heads,\n",
        "                   'ff_dim': self.ff_dim,\n",
        "                   'attn_heads': self.attn_heads,\n",
        "                   'dropout_rate': self.dropout_rate})\n",
        "    return config          "
      ],
      "metadata": {
        "id": "BGJl68JqKH6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# create the first transformer without time_to_vector\n",
        "def create_transformer_one():\n",
        "  batch_size = 32\n",
        "  seq_len = 500\n",
        "\n",
        "  d_k = 256\n",
        "  d_v = 256\n",
        "  n_heads = 12\n",
        "  ff_dim = 256 \n",
        "   \n",
        "  '''Initialize time and transformer layers'''\n",
        "  time_embedding = Time2Vector(seq_len)\n",
        "  attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "  attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "  attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "\n",
        "  '''Construct model'''\n",
        "  in_seq = Input(shape=(seq_len, 1))\n",
        "  x = time_embedding(in_seq)\n",
        "  x = Concatenate(axis=-1)([in_seq, x])\n",
        "  x = attn_layer1((x, x, x))\n",
        "  x = attn_layer2((x, x, x))\n",
        "  x = attn_layer3((x, x, x))\n",
        "  x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
        "  x = Dropout(0.1)(x)\n",
        "  x = Dense(256, activation='relu')(x)\n",
        "  x = Dropout(0.1)(x)\n",
        "  x = Dense(64, activation='relu')(x)\n",
        "  x = Dropout(0.1)(x)\n",
        "  out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "  model = Model(inputs=in_seq, outputs=out)\n",
        "  model = load_model(\"./transformer_time2vec\")\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"binary_accuracy\"])\n",
        "  \n",
        "  return model\n"
      ],
      "metadata": {
        "id": "xYR1Upq2KH87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create sklearn voting classer wraper for Keras model\n",
        "time2vec = keras.wrappers.scikit_learn.KerasClassifier(lambda: create_model(),\n",
        "                                                  epochs=10, batch_size=16,\n",
        "                                                  verbose=True)\n",
        "time2vec._estimator_type = \"classifier\""
      ],
      "metadata": {
        "id": "0CaEt8WDMFB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ],
      "metadata": {
        "id": "ogPLenaAWm7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip pre-trained model of the second transformer \n",
        "!tar -xvf ./ICNA_hackathon/transformer_ba.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZNh7Lxm__qe",
        "outputId": "0f1680fa-6589-4718-f2db-03de1c56b209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./transformer_ba/\n",
            "./transformer_ba/keras_metadata.pb\n",
            "./transformer_ba/variables/\n",
            "./transformer_ba/variables/variables.index\n",
            "./transformer_ba/variables/variables.data-00000-of-00001\n",
            "./transformer_ba/saved_model.pb\n",
            "./transformer_ba/assets/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1)(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res\n",
        "\n",
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    # outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    model = load_model(\"./transformer_ba\")\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        metrics=[\"binary_accuracy\"],)\n",
        "    \n",
        "    \n",
        "    return model\n",
        "  \n",
        "    \n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose=1)"
      ],
      "metadata": {
        "id": "G3-NEzM8-pW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e263492a-6513-4266-c6c5-4c3e63955378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 4s 81ms/step - loss: 0.3693 - binary_accuracy: 0.8371\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3692592680454254, 0.8371211886405945]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create sklearn voting classer wraper for Keras model\n",
        "transformer = keras.wrappers.scikit_learn.KerasClassifier(lambda: build_model(\n",
        "                                                                              input_shape,\n",
        "                                                                              head_size=256,\n",
        "                                                                              num_heads=4,\n",
        "                                                                              ff_dim=4,\n",
        "                                                                              num_transformer_blocks=4,\n",
        "                                                                              mlp_units=[128],\n",
        "                                                                              mlp_dropout=0.4,\n",
        "                                                                              dropout=0.25,), \n",
        "                                                          epochs=1, batch_size=64,verbose=True)\n",
        "transformer._estimator_type = \"classifier\""
      ],
      "metadata": {
        "id": "G01XFpNOAN2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "voting2 = VotingClassifier(estimators=[(\"Time2vec\",time2vec), (\"Transformer\", transformer)], voting='soft',flatten_transform=True)\n",
        "voting2.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhXGWfGPjvme",
        "outputId": "9ad26425-0b5c-45b2-da49-489cc55da63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "226/226 [==============================] - 89s 327ms/step - loss: 0.4932 - binary_accuracy: 0.7667\n",
            "Epoch 2/10\n",
            "226/226 [==============================] - 73s 325ms/step - loss: 0.4514 - binary_accuracy: 0.7998\n",
            "Epoch 3/10\n",
            "226/226 [==============================] - 75s 330ms/step - loss: 0.4276 - binary_accuracy: 0.8103\n",
            "Epoch 4/10\n",
            "226/226 [==============================] - 74s 325ms/step - loss: 0.3939 - binary_accuracy: 0.8295\n",
            "Epoch 5/10\n",
            "226/226 [==============================] - 73s 325ms/step - loss: 0.3617 - binary_accuracy: 0.8517\n",
            "Epoch 6/10\n",
            "226/226 [==============================] - 73s 325ms/step - loss: 0.3285 - binary_accuracy: 0.8636\n",
            "Epoch 7/10\n",
            "226/226 [==============================] - 73s 325ms/step - loss: 0.2988 - binary_accuracy: 0.8759\n",
            "Epoch 8/10\n",
            "226/226 [==============================] - 73s 325ms/step - loss: 0.2682 - binary_accuracy: 0.8911\n",
            "Epoch 9/10\n",
            "226/226 [==============================] - 73s 325ms/step - loss: 0.2440 - binary_accuracy: 0.9047\n",
            "Epoch 10/10\n",
            "226/226 [==============================] - 73s 325ms/step - loss: 0.2400 - binary_accuracy: 0.9064\n",
            "57/57 [==============================] - 32s 497ms/step - loss: 0.2517 - binary_accuracy: 0.8995\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('Transformer',\n",
              "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f9d84273190>),\n",
              "                             ('Time2vec',\n",
              "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f9d99936550>),\n",
              "                             ('Transformer',\n",
              "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f9d99943790>)],\n",
              "                 voting='soft')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "y_pred = voting2.predict(x_test)\n",
        "y_pred = np.where(y_pred > 0.5,1,0)\n",
        "\n",
        "\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_pred)\n",
        "print(cm)\n",
        "print(balanced_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYB-BkEB8dRZ",
        "outputId": "a461160e-f311-47e5-91f6-4bb58c899349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[627  54]\n",
            " [ 65 574]]\n",
            "0.9094917030326846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "plot_confusion_matrix(voting2, x_test, y_test)  \n",
        "plt.savefig(\"confusion_matrix_90.png\", dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "R1UxWOZm3MWX",
        "outputId": "17a700e5-6b86-4a3e-adef-62b0a2eb86e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V0g7mFivGs0C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
